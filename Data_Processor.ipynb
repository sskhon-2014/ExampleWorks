{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data from an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Reads in HTML file with matched abstracts from Perl script and outputs excel sheet with relevant columns.\n",
    "\"\"\"\n",
    "\n",
    "data = open('data-03-06-2018.html', encoding=\"utf-8\")\n",
    "soup = BeautifulSoup(data, 'lxml')\n",
    "\n",
    "data_dict = {'Article': [], 'Link': [], 'Journal': [], 'Abstract': [], 'PMID': [], 'Sentence Scope': []}\n",
    "\n",
    "def is_valid(index, arr):\n",
    "    return index >= 0 and index < len(arr)\n",
    "\n",
    "for a in soup.find_all('a'):\n",
    "    data_dict['Article'].append(a.text)\n",
    "    data_dict['Link'].append(a['href'])\n",
    "    uids = re.search(r'\\d{7,}', a['href']) # Some of the links have multiple PMIDs (citated articles)\n",
    "    if uids.group() == \"8\" or uids.group() == \"9\": # 7 digit PMID (Hardcoded for 1997-2007)\n",
    "        data_dict['PMID'].append(uids.group()[:7])\n",
    "    else: # 8 digit PMID\n",
    "        data_dict['PMID'].append(uids.group()[:8])\n",
    "for p in soup.find_all('p', id='Journal'):\n",
    "    data_dict['Journal'].append(p.text)\n",
    "for p in soup.find_all('p', id='Abstract'):\n",
    "    data_dict['Abstract'].append(p.text)\n",
    "    sentences = re.findall(r'[^.!?\\s][^.!?]*(?:[.!?](?![\\'\\\"]?\\s|$)[^.!?]*)*[.!?]?[\\'\\\"]?(?=\\s|$)', p.text)\n",
    "    match = [\"% sensitivity\", \"% specificity\"]\n",
    "    found = False\n",
    "    index = 0\n",
    "    upstream, downstream = \"\", \"\"\n",
    "    for sentence in sentences:\n",
    "        if any(x in sentence for x in match):\n",
    "            if is_valid(index - 2, sentences):\n",
    "                upstream = sentences[index - 2] + sentences[index - 1]\n",
    "            elif is_valid(index - 1, sentences):\n",
    "                upstream = sentences[index - 1]\n",
    "            if is_valid(index + 2, sentences):\n",
    "                downstream = sentences[index + 1] + sentences[index + 2]\n",
    "            elif is_valid(index + 1, sentences):\n",
    "                downstream = sentences[index + 1]\n",
    "            data_dict['Sentence Scope'].append(upstream + \" \" + sentences[index] + \" \" + downstream)\n",
    "            found = True\n",
    "            break\n",
    "        index += 1\n",
    "    if not found:\n",
    "        data_dict['Sentence Scope'].append(\"Sentences not found\") # after bug fix, no instances w/o match\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dict)\n",
    "df.head()\n",
    "\n",
    "# Removing duplicates based on Article Title\n",
    "df = df.drop_duplicates('Article')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Converting data into Excel sheet\n",
    "from pandas import ExcelWriter\n",
    "writer = ExcelWriter('ProcessedData.xlsx')\n",
    "df.to_excel(writer)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
